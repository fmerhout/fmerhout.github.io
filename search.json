[{"authors":["CA Bail","B Guay","E Maloney","A Combs","DS Hillygus","F Merhout","D Freelon","A Volfovsky"],"categories":null,"content":"","date":1580446800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580446800,"objectID":"d3a2d75545d0a47ea5abdcd601cdbdab","permalink":"/publication/bail-etal-2020/","publishdate":"2020-01-31T00:00:00-05:00","relpermalink":"/publication/bail-etal-2020/","section":"publication","summary":"There is widespread concern that Russia and other countries have launched social-media campaigns designed to increase political divisions in the United States. Though a growing number of studies analyze the strategy of such campaigns, it is not yet known how these efforts shaped the political attitudes and behaviors of Americans. We study this question using longitudinal data that describe the attitudes and online behaviors of 1,239 Republican and Democratic Twitter users from late 2017 merged with nonpublic data about the Russian Internet Research Agency (IRA) from Twitter. Using Bayesian regression tree models, we find no evidence that interaction with IRA accounts substantially impacted 6 distinctive measures of political attitudes and behaviors over a 1-mo period. We also find that interaction with IRA accounts were most common among respondents with strong ideological homophily within their Twitter network, high interest in politics, and high frequency of Twitter usage. Together, these findings suggest that Russian trolls might have failed to sow discord because they mostly interacted with those who were already highly polarized. We conclude by discussing several important limitations of our study—especially our inability to determine whether IRA accounts influenced the 2016 presidential election—as well as its implications for future research on social media influence campaigns, political polarization, and computational social science.","tags":[],"title":"Assessing the Russian Internet Research Agency’s impact on the political attitudes and behaviors of American Twitter users in late 2017","type":"publication"},{"authors":["Friedolin Merhout"],"categories":null,"content":"From June 17 to June 28, 2019, I had the pleasure of co-organizing the Summer Institute in Computational Social Science 2019 partner site in Los Angeles. Besides meeting 41 bright, inspiring young computational social science scholars from Southern California and beyond, I have been fortunate to work with my amazing co-organizers Alina Arseniev-Koehler, Bernard Koch, Marcel Roman, Pablo Geraldo, Mike Tzen, and Jennie E. Brand. The partner site was hosted by the California Center for Population Research (CCPR) at the University of California and used facilities at the Luskin School for Public Affairs. Topically, the Los Angeles Institute added an additional focus on Machine Learning and Causal Inference to the broader computational social science schedule common to all SICSS partner sites. The following report provides a brief summary of the different stages of the institute, of what we, the organizers, perceive to have gone well, and where we experienced challenges.\nApplications and Admissions The SICSS-Los Angeles partner site faced a somewhat unique set of circumstances regarding timing, location, and funding that broadly influenced the overall application and admission processes. First, the partner site took shape after most other sites had already formed. Given this, we were working with a shorter timeline for the applications and admission processes which led us to simplify the application procedures substituting a one-page letter of interest for the writing sample and letter(s) of recommendation other partner sites required. Second, as the only partner site on the West Coast and given the Institutes location in commuting distance to more than a handful of institutions of higher education, the partner site was serving a very large pool of potential participants. Finally, the partner site had a close association with CCPR and a unique, additional topical focus. This increased the appeal to a broad but specific audience affiliated with the center and or interested in causal inference and machine learning.\nIn addition to these site-specific factors, we engaged in a very proactive recruitment strategy using the ASA methodology section listserv, the Google Computational Sociology group, and various social science departmental email lists at major universities across California. Also, the partner site benefited from a long list of distinguished guest speakers which additionally increased the interest among potential participants. All of these factors contributed to a very robust and diverse pool of applications, despite our inability to offer financial assistance for travel or housing like some of the other sites.\nIn our approach to admissions, we strove to be comprehensive and assess all applicants holistically. That meant three of the organizers reviewed all the application materials for each of the 72 applications independently and then combined their assessments to make final admissions determinations. In the independent application reviews, we paid attention to how well the letter of interest articulated what applicants hoped to take from participation, whether applicants promised to benefit from participation (i.e. weren’t too advanced), and how they might contribute to disciplinary and institutional diversity among the participant pool.\nIn all, we admitted 41 participants which placed our partner site at the upper end of Institute sizes. To us, this number seemed to be strike a reasonable balance between extending this opportunity to as many people as possible without running the risk of group dynamics that might undermine the learning experience. Additionally, we reasoned that partner sites experience higher attrition, so a large group to start was desirable to attain a good effective number of participants.\nOverall, we did not experience major issues with the applications and admissions process but did find minor areas for improvement. First, the specific expectations for the letter of intent could be stated more clearly. Since this was applicants’ only chance to present themselves beside their CV, it had a strong influence on admission decisions. The letters we received varied widely in detail and thoroughness, and with clearer expectations decisions could be more easily justified. Second, while the number of participants did not affect our budget, the admission process might be streamlined with a preset goal. Finally, we used a dedicated email account for the institute which we could have used more efficiently by clearly distributing monitoring responsibilities.\nPre-Arrival For our pre-arrival preparations we relied heavily on the resources provided by the main site. We generally used the main site emails as templates and adjusted the language as appropriate for our situation. In our case, with one key organizer not being local, the work of figuring out the specifics of the partner site rested mainly with one other organizer. Luckily, we had great support from the CCPR administrators which immensely reduced the logistical work for the organizers.\nOverall, we aimed to hit the sweet spot between too many emails, too long emails, and too little information. In our case, this meant one major email to all accepted participants after admissions were completed and another reminder email the week before the institute. Similar to the main site, the former email contained primarily information about what we expected participants to do before the institute and what they could expect from the institute. The latter email reiterated logistical information to remind participants of all they needed to know to arrive prepared and on time for the first day of the institute.\nGiven our experience, there were at least three aspects that we would try to improve upon in future iterations of the institute. First, participants did not appear to take advantage of the pre-institute learning opportunities which led to some hiccups during the beginning of the institute. While the particular situation surrounding DataCamp might have contributed to this, we think this could be improved by reviewing and following up with those individuals who indicated no or little experience with R or a programming language in the weeks leading up to the institute (and similarly for those who indicated having no social science background). Second, we did not appear to have succeeded in converting participants to using Slack which impacted communication before and during the institute. By requiring participants to send us a gif on Slack or dedicating a short segment at the beginning of the institute, this might be improved upon. Finally, with any partner site that draws a largely commuting participant pool, parking will be an issue. By communicating the options and alternatives to individual traffic more clearly up front and potentially even querying it during the application process, this might be solved more elegantly.\nWeek 1 Since we realized that we would not be able to recreate the engrossing holistic experience of the main site or some of the other partner sites, our aim with SICSS-Los Angeles was to provide a topically unique experience. To this end, we modified the schedule for the first week keeping about 80% of the main site’s content and supplementing it with lectures, exercises, and guest speakers on Machine Learning and Causal Inference. This topical focus appeared to resonate with a wide swath of applicants and participants but also required us to make some tough decisions about cutting and or condensing content from the well thought out general SICSS schedule. One blessing and curse that our partner site had in making this condensed schedule work was the time difference, which allowed us to skip and or localize Q\u0026amp;As that might be less engaging, make use of Youtube’s replay speed options, and generally skip over downtime in the stream.\nGiven that we were only meeting Monday through Friday, our schedule was already too tight to allow us to cover all materials from the main site. Once we did cut some content, we also freed ourselves mentally to rearrange some of the organizational elements in a way that seemed more beneficial to a partner site experience. Specifically, we moved the Research Speed Dating exercise to Friday morning which allowed participants to 1) have a known goal and purpose for returning for the second week and 2) use the weekend to arrange their group’s meeting schedule, since commuting to the Institute site was not practical for everyone.\nAnother partner site issue we aimed to address is the less engrossing experience of watching pre-recorded lectures compared to watching them in person or live. Our approach to this issue was to replace some of the recorded content with in person lectures by the organizers. As hoped, this solution was more engaging for participants but, as the lectures from the main site are top tier, also required a substantial amount of preparation to match the quality of instruction. By distributing the instruction load across multiple organizers we made these time commitments feasible for all involved but also ended up with uneven quality of instruction. For future iterations we would strive to agree on clear standards and ideally review the local content before the start of the institute.\nWeek 2 Our second week was marked by a lot of flexibility which benefited some of the groups that formed on the Friday prior but also led to some unanticipated issues. We aimed to provide access to the same facilities used for the first week of the Institute during business hours the second week, while reducing demands on organizers by having one to two organizers continuously present. This mostly worked out despite some organizational hiccups with accessing the facilities. However, the discontinuity in organizers present was not optimal for advising research group projects since no one organizer was aware of all that had been going on. For future iterations, such continuity in the second week seems desirable.\nIn addition to moving the Research Speed Dating to the Friday of the first week, we had to move the research funding process to the second week for administrative purposes. This had the beneficial side effect of groups being able to draw on organizers to give feedback on the feasibility of the proposal. Unfortunately, it also distracted some participants from the research projects their group had decided to pursue and left others scratching their heads for what resources they might require or ask for. If the budget and timeline of future iterations allows it, it seems to be better to follow the funding timeline set by the main site.\nOverall, the groups that completed projects during the second week were very successful and we were impressed with the wide variety of projects that emerged from the institute, which drew on an even wider set of computational methods and sources than we had managed to cover during the first week. An unfortunate development we experienced was that, as the day progressed, more and more participants left. This was partially due to outside commitments that could not be changed but for some also appeared to result from a lacking sense of Gemeinschaft. This is something we as organizers would hope to improve upon in future iterations by emulating some of the social events surrounding the Institute that the main site and partner sites outside of the US have been exemplifying.\nPost-Institute While many groups and participants have expressed interest to pursue the projects started in week 2, this might be a challenge as everyone returns to their respective home institutions. One fortuitous impulse we were able to set to encourage the continuation of the projects was to invite a few of them to present at a CCPR event one month after the conclusion of the Institute. This is clearly not feasible for all partner sites. Where it is possible, however, inviting groups to present at a later date seems like a worthwhile endeavor to promote the growth of the networks and the projects the Institutes help to start.\nOverall, the Los Angeles partner site of the Summer Institute for Computational Social Science was a success in showcasing and bringing together the emerging CSS community in (Southern) California! We want to thank Chris Bail, Matt Salganik, and Jennie Brand for providing us and the participants with this unique opportunity, and CCPR, Ana Ramirez, and Lucy Shao for their generous financial and outstanding organizational support.\n        ","date":1566446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566446400,"objectID":"8e39a17a0eee41d3357f4ec571caca76","permalink":"/post/sicss-ucla-postmortem/","publishdate":"2019-08-22T00:00:00-04:00","relpermalink":"/post/sicss-ucla-postmortem/","section":"post","summary":"Two-weeks of intense computational social sciencing in the rearview mirror.","tags":["SICSS","computational social science","ucla"],"title":"Post-Mortem: SICSS 2019, Los Angeles Partner Site","type":"post"},{"authors":["F Merhout","J Doyle"],"categories":null,"content":"","date":1563854400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563854400,"objectID":"5ea9d7ef5a615539a2f365bd9d08d6f4","permalink":"/publication/merhout-doyle-2019/","publishdate":"2019-07-23T00:00:00-04:00","relpermalink":"/publication/merhout-doyle-2019/","section":"publication","summary":"Objective: To investigate the existence and trajectory of diet disparities among college students from different socioeconomic statuses (SESs). Methods:A random sample of freshman and sophomore students was invited to participate in an online survey on eating behaviors. Ordinary least squares regressions were fit to 148 complete responses to examine the association between family income ≤200% of the federal poverty level and overall, healthy, and unhealthy food consumption. Results: Low-SES students reported eating significantly more unhealthy food during their freshman year than their non–low-SES peers. This difference is not statistically significant for second-year students and robust to on-campus spending power. Conclusions and Implications: Disparities in diets for students from different socioeconomic backgrounds that were observed in the freshman year of college were absent in the sophomore year. Awareness of these disparities and trend is important to broadly promote healthy eating.","tags":[],"title":"Does Socioeconomic Status Determine Diet Quality if Food Access, Resources, and Nutrition Education are Equalized? An Exploration of College Student Diets","type":"publication"},{"authors":["Friedolin Merhout"],"categories":null,"content":"I am excited to announce that I will be co-organizing a partner site for the 2019 Summer Institute in Computational Social Science (SICSS) together with Alina Arseniev-Koehler and Jennie E. Brand in beautiful Southern California. SICSS-Los Angeles will run from Monday, June 17 to Friday, June 28, 2019 at the University of California at Los Angeles (UCLA). Thanks to generous funding from the California Center for Population Research (CCPR) there is no cost to participate, and we will provide refreshments for all on-site days.\nThe purpose of the Summer Institute is to bring together graduate students, postdoctoral researchers, and early career faculty interested in computational social science. The Summer Institute is open to both social scientists and data scientists, broadly conceived. In coordination with the main Summer Institute site at Princeton, we will cover topics ranging from text analysis and online field experiments to and digital data collection and ethics. The Los Angeles partner site will additionally add a site-specific focus on machine-learning methods for causal inference.\nApplications are open through April 14, 11:59 PM PST, to all interested individuals regardless of location. Details about eligibility and application procedures can be found here\nNB: We are in the process of finalizing the schedule and will post updates to the partner site website as they become available.\nGeneral info  organizers:  Friedolin Merhout Alina Arseniev-Koehler Jennie E. Brand   location:  UCLA, Details TBD.   date:  June 17-28, 2019.         ","date":1550898000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1550898000,"objectID":"b9fa8a6e32b20ac176dfeca2fa02bd57","permalink":"/post/sicss-ucla/","publishdate":"2019-02-23T00:00:00-05:00","relpermalink":"/post/sicss-ucla/","section":"post","summary":"Two-week immersive summer school for social and data scientists interested in computational social science.","tags":["SICSS","computational social science","ucla"],"title":"Summer Institute in Computational Social Science 2019, Los Angeles Partner Site","type":"post"},{"authors":["CA Bail","LP Argyle","TW Brown","JP Bumpus","H Chen","MB Fallin Hunzaker","J Lee","ML Mann","F Merhout","A Volfovsky"],"categories":null,"content":"","date":1535428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535428800,"objectID":"bfbc85e6aff64518068d99f6c7582bad","permalink":"/publication/bail-etal-2018/","publishdate":"2018-08-28T00:00:00-04:00","relpermalink":"/publication/bail-etal-2018/","section":"publication","summary":"There is mounting concern that social media sites contribute to political polarization by creating “echo chambers” that insulate people from opposing views about current events. We surveyed a large sample of Democrats and Republicans who visit Twitter at least three times each week about a range of social policy issues. One week later, we randomly assigned respondents to a treatment condition in which they were offered financial incentives to follow a Twitter bot for 1 month that exposed them to messages from those with opposing political ideologies (e.g., elected officials, opinion leaders, media organizations, and nonprofit groups). Respondents were resurveyed at the end of the month to measure the effect of this treatment, and at regular intervals throughout the study period to monitor treatment compliance. We find that Republicans who followed a liberal Twitter bot became substantially more conservative posttreatment. Democrats exhibited slight increases in liberal attitudes after following a conservative Twitter bot, although these effects are not statistically significant. Notwithstanding important limitations of our study, these findings have significant implications for the interdisciplinary literature on political polarization and the emerging field of computational social science.","tags":[],"title":"Exposure to opposing views on social media can increase political polarization","type":"publication"},{"authors":null,"categories":null,"content":"This course was offered in the Spring 2021 at the University of Copenhagen's Department of Sociology. The background readings for the course come from Gabriel Ignatow and Rada Mihalcea's Text Mining: A Guidebook for the Social Sciences while much of the applied readings come from Julia Silge and David Robinson's Text Mining with R and Emil Hvitfeldt and Julia Silge's Supervised Machine Learning for Text Analysis in R. You can find the course syllabus here and further course information on the university's course listing site.\nCourse Description Our contemporary, increasingly digital societies generate vast amounts of textual data that provide a rich source for sociological research. The scale of these novel data however poses a challenge to the approaches sociologists traditionally use to study texts. In response, automated methods of text analysis are becoming increasingly popular and the command of these methods a valuable skill in academic environments as well as on the private industry job market.\nThis course introduces students to quantitative text analysis, reviews selected methods falling within this category of approaches, and illustrates their implementation in the statistical programming language R. Students will learn about the origins of quantitative approaches to studying text and how they complement traditional, qualitative methodologies. Using recent peer-reviewed publications students will gain an understanding of how these methodological approaches can be used to answer sociological questions and, in hands-on lab sessions, students will learn to implement selected techniques in R.\nAfter successful participation, students will be comfortable reading current sociological research using quantitative text analysis, have an understanding of the landscape of tools used within the literature, and will have gained experience with their implementation in R.\n","date":1534910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534910400,"objectID":"1ed2122da3c2a45aa76a62e9dbadc886","permalink":"/teaching/mtw/","publishdate":"2018-08-22T00:00:00-04:00","relpermalink":"/teaching/mtw/","section":"teaching","summary":"An introductory level course for learning quantitative text analysis methods and their implementation in R.","tags":["quantitative text analysis","R","textnets"],"title":"More Than Words: Introduction to Quantitative Text Analysis","type":"teaching"},{"authors":null,"categories":null,"content":"The Hoover Institution recently finished digitizing 586 Nazi biograms collected by Theodore Abel, professor of sociology at Columbia University from 1929 to 1950. Abel gathered these documents a year after Hitler's appointment as chancellor by setting up a contest offering 400 German marks \u0026ldquo;for the best personal life history of an adherent of the Hitler movement.\u0026rdquo; The collection which represents a sample of 2.5% of early NSDAP members forms the basis for Abel's insightful book Why Hitler Came Into Power published in 1938.\nWith the increasing sophistication of quantitative text analysis coinciding with the public release of the collection, we are now presented with the opportunity to reanalyze these data with computational methods. Earlier applications of such methods already highlighted the value of these data to reveal the narrative structures of becoming and being a Nazi, but to leverage the full potential of new computational methods the complete collection needs to be converted into a machine readable format. To create these machine readable files, this project will use the optical character recognition software from the leader in the field ABBYY which is accessible through their cloud based ABBYY OCR SDK.\n","date":1534910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534910400,"objectID":"8de4a22974e5988b290a5fe8130a9b2f","permalink":"/project/nazi-biograms/","publishdate":"2018-08-22T00:00:00-04:00","relpermalink":"/project/nazi-biograms/","section":"project","summary":"Analysis of Nazi biograms collected by Theodore Abel.","tags":["quantitative text analysis","textnets","Nazi biograms"],"title":"Quantitative Text Analysis of NSDAP Member Autobiographies","type":"project"},{"authors":["Friedolin Merhout"],"categories":null,"content":"I am excited to be given the opportunity to co-host a tutorial on the textnets package for R at the 2018 European Symposium Series on Societal Challenges with my amazing colleagues Taylor Brown and Marcus Mann. The symposium will take place in Cologne, Germany from December 5 to 7 with our workshop and many more scheduled for the first day of the event.\nNB: This post describes the tentative schedule and will be updated as we finalize the details for the tutorial.\nGeneral info  organizers:  Friedolin Merhout Taylor W. Brown Marcus L. Mann   location:  Cologne. Details TBD.   date:  December 5, 2018.    Description The tutorial will introduce participants to a newly developed R package that leverages techniques from network analysis/graph theory to improve and innovate on approaches to automated text analysis. There is growing interest in automated detection of latent themes in large-scale, unstructured text data. While topic models have become a popular choice for such tasks, our alternative provides several significant advantages over these conventional \u0026ldquo;bag of words\u0026rdquo; models. Three distinct advantages of our network-based approach are: 1) the potential to apply the concept of triadic closure to identify the meaning of words, i.e. the meaning of any two connected words can be understood more accurately in the context of a third word; 2) the greater flexibility in document length compared to the generally required long texts for topic models, which is a significant advantage in an age where short social media messages are pervasive; and 3) the incorporation of recent advances in community detection, which provides an innovative way to group words and documents by leveraging clustering observed within networks.\nTutorial participants will acquire a robust understanding of the fundamentals of both automated text analysis and network analysis, and will be encouraged to explore how their combination can improve upon existing text analysis methods. The main objective of the tutorial will be to enable participants to apply textnets methods to their own research questions using our R package. In doing so, participants will develop the skills to tailor the existing functionality of the package to their particular needs. As a second objective and in the spirit of open science, participants will be introduced to the tools and given the opportunity to contribute to our open-source repository on Github–suggesting changes or extending the functionality of the package for the benefit of future users.\nSchedule The tentative structure of the tutorial will be as follows:\nIntroduction and motivation for the textnets package  What is automated text analysis, what are its applications, and what are its limitations?  History: Content analysis Methods: Topic models and word embeddings Limitations of current methods   What is network analysis and how can it address these limitations?  Network analysis basics: nodes, edges, network measures Meaning from triadic relationships Lower threshold for required text lengths Two mode networks and their visual representation (documents connected by words and vice versa) Network measures \u0026amp; community detection Polar ties for opposing views on topic    Introduction of the package and example application  What is the textnets package, what are its functions and their arguments?  Input data format Preparing text data Creating text networks Visualizing text networks Interpreting text networks Measuring brokerage   The US gun debate on Twitter - a textnets application  Introduction of corpora of tweets Show preparation of tweets Identifying communities in Twitter account text network Identifying topics in communities    Hands-on example application and brainstorming application ideas  BYOData or try out textnets on a dataset we provide Small group discussions to identify promising applications  Concluding presentations and discussion  Present participant-generated text networks Discussion of brainstorming ideas Future textnets developments        ","date":1534910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535428800,"objectID":"e4ec681f72632bce8443594effed5cf4","permalink":"/post/textnets-tutorial/","publishdate":"2018-08-22T00:00:00-04:00","relpermalink":"/post/textnets-tutorial/","section":"post","summary":"Learn how to combine quantitative text analysis with graph theory in Cologne in December.","tags":["workshop","textnets","#eurocss"],"title":"textnets tutorial at #eurocss","type":"post"},{"authors":["CA Bail","F Merhout","P Ding"],"categories":null,"content":"","date":1534824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534824000,"objectID":"1e3eecacfe860af70185d80d5e64bae9","permalink":"/publication/bail-merhout-ding-2018/","publishdate":"2018-08-21T00:00:00-04:00","relpermalink":"/publication/bail-merhout-ding-2018/","section":"publication","summary":"Recent terrorist attacks by first- and second-generation immigrants in the United States and Europe indicate that radicalization may result from the failure of ethnic integration—or the rise of intergroup prejudice in communities where “home-grown” extremists are raised. Yet, these community-level drivers are notoriously difficult to study because public opinion surveys provide biased measures of both prejudice and radicalization. We examine the relationship between anti-Muslim and pro-ISIS (Islamic State of Iraq and Syria) Internet searches in 3099 U.S. counties between 2014 and 2016 using instrumental variable models that control for various community-level factors associated with radicalization. We find that anti-Muslim searches are strongly associated with pro-ISIS searches—particularly in communities with high levels of poverty and ethnic homogeneity. Although more research is needed to verify the causal nature of this relationship, this finding suggests that minority groups may be more susceptible to radicalization if they experience discrimination in settings where they are isolated and therefore highly visible—or in communities where they compete with majority groups for limited financial resources. We evaluate the validity of our findings using several other data sources and discuss the implications of our findings for the study of terrorism and intergroup relations, as well as immigration and counterterrorism policies.","tags":[],"title":"Using Internet search data to examine the relationship between anti-Muslim and pro-ISIS sentiment in U.S. counties","type":"publication"},{"authors":null,"categories":null,"content":"\u0026hellip;\n","date":1530158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530158400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2018-06-28T00:00:00-04:00","relpermalink":"/privacy/","section":"","summary":"\u0026hellip;","tags":null,"title":"Privacy Policy","type":"page"}]